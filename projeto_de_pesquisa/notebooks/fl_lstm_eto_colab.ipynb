{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a05bb051",
      "metadata": {
        "id": "a05bb051"
      },
      "source": [
        "# Aprendizado Federado com LSTM para Estimativa de ETo\n",
        "\n",
        "Notebook compatível com **Google Colab**, derivado do script `fl_lstm_eto.py`.\n",
        "\n",
        "Este notebook:\n",
        "- Define o modelo LSTM\n",
        "- Simula Aprendizado Federado (FedAvg)\n",
        "- Executa treinamento e avaliação por rounds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bf8669f7",
      "metadata": {
        "id": "bf8669f7"
      },
      "outputs": [],
      "source": [
        "# Instalação (Colab)\n",
        "# Normalmente já disponível, mas mantido por segurança\n",
        "!pip install -q numpy pandas scikit-learn torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "52c8d08f",
      "metadata": {
        "id": "52c8d08f"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os, math, random\n",
        "from typing import List, Dict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "49bb2d2e",
      "metadata": {
        "id": "49bb2d2e"
      },
      "outputs": [],
      "source": [
        "# Reprodutibilidade\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "829666e3",
      "metadata": {
        "id": "829666e3"
      },
      "outputs": [],
      "source": [
        "# Métrica\n",
        "def rmse(y_true, y_pred):\n",
        "    return math.sqrt(mean_squared_error(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e7148bc2",
      "metadata": {
        "id": "e7148bc2"
      },
      "outputs": [],
      "source": [
        "# Dataset com janelas temporais\n",
        "class WindowDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X.astype('float32')\n",
        "        self.y = y.astype('float32')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx]), torch.tensor(self.y[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "75d8c1cd",
      "metadata": {
        "id": "75d8c1cd"
      },
      "outputs": [],
      "source": [
        "# Criação das janelas\n",
        "def make_windows_from_df(df, feature_cols, target_col, seq_len, scaler=None, fit_scaler=True):\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    X_raw = df[feature_cols].values.astype(float)\n",
        "    y_raw = df[target_col].values.astype(float)\n",
        "\n",
        "    if scaler is None:\n",
        "        scaler = StandardScaler()\n",
        "    if fit_scaler:\n",
        "        scaler.fit(X_raw)\n",
        "\n",
        "    Xs = scaler.transform(X_raw)\n",
        "    X_windows, y_windows = [], []\n",
        "\n",
        "    for i in range(seq_len, len(Xs)):\n",
        "        X_windows.append(Xs[i-seq_len:i])\n",
        "        y_windows.append(y_raw[i])\n",
        "\n",
        "    if len(X_windows) == 0:\n",
        "        return None, None, scaler\n",
        "\n",
        "    return np.stack(X_windows), np.array(y_windows), scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cef7daf1",
      "metadata": {
        "id": "cef7daf1"
      },
      "outputs": [],
      "source": [
        "# Modelo LSTM\n",
        "class LSTMRegressor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.2, bidirectional=False):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_size * self.num_directions, hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        last = out[:, -1, :]\n",
        "        return self.fc(last).squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c3c84a5d",
      "metadata": {
        "id": "c3c84a5d"
      },
      "outputs": [],
      "source": [
        "# Cliente Federado\n",
        "class FLClient:\n",
        "    def __init__(self, client_id, df, feature_cols, target_col, seq_len,\n",
        "                 device='cpu', batch_size=32, local_epochs=1, lr=1e-3):\n",
        "\n",
        "        self.client_id = client_id\n",
        "        self.feature_cols = feature_cols\n",
        "        self.target_col = target_col\n",
        "        self.seq_len = seq_len\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.local_epochs = local_epochs\n",
        "        self.lr = lr\n",
        "\n",
        "        n = len(df)\n",
        "        cutoff = int(n * 0.8) if n > 10 else int(n * 0.7)\n",
        "        df_train = df.iloc[:cutoff]\n",
        "        df_test = df.iloc[cutoff:]\n",
        "\n",
        "        X_tr, y_tr, self.scaler = make_windows_from_df(\n",
        "            df_train, feature_cols, target_col, seq_len\n",
        "        )\n",
        "        X_te, y_te, _ = make_windows_from_df(\n",
        "            df_test, feature_cols, target_col, seq_len, scaler=self.scaler, fit_scaler=False\n",
        "        )\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            WindowDataset(X_tr, y_tr), batch_size=batch_size, shuffle=True\n",
        "        )\n",
        "        self.test_loader = DataLoader(\n",
        "            WindowDataset(X_te, y_te), batch_size=batch_size, shuffle=False\n",
        "        ) if X_te is not None else None\n",
        "\n",
        "        self.n_samples = len(y_tr)\n",
        "\n",
        "        self.model = LSTMRegressor(input_size=len(feature_cols)).to(device)\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "    def get_weights(self):\n",
        "        return {k: v.cpu().clone() for k, v in self.model.state_dict().items()}\n",
        "\n",
        "    def set_weights(self, state_dict):\n",
        "        self.model.load_state_dict(state_dict)\n",
        "\n",
        "    def local_train(self):\n",
        "        self.model.train()\n",
        "        for _ in range(self.local_epochs):\n",
        "            for xb, yb in self.train_loader:\n",
        "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
        "                loss = self.criterion(self.model(xb), yb)\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "    def evaluate_local(self):\n",
        "        if self.test_loader is None:\n",
        "            return {}\n",
        "        self.model.eval()\n",
        "        y_true, y_pred = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in self.test_loader:\n",
        "                preds = self.model(xb.to(self.device)).cpu().numpy()\n",
        "                y_pred.extend(preds)\n",
        "                y_true.extend(yb.numpy())\n",
        "        return {\n",
        "            'rmse': rmse(y_true, y_pred),\n",
        "            'mae': mean_absolute_error(y_true, y_pred),\n",
        "            'r2': r2_score(y_true, y_pred)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a8b7612d",
      "metadata": {
        "id": "a8b7612d"
      },
      "outputs": [],
      "source": [
        "# Servidor Federado\n",
        "class FLServer:\n",
        "    def __init__(self, clients, device='cpu'):\n",
        "        self.clients = clients\n",
        "        self.device = device\n",
        "        self.global_model = LSTMRegressor(\n",
        "            input_size=len(clients[0].feature_cols)\n",
        "        ).to(device)\n",
        "\n",
        "    def aggregate(self, states, weights):\n",
        "        new_state = {}\n",
        "        total = sum(weights)\n",
        "        for k in states[0]:\n",
        "            new_state[k] = sum(\n",
        "                sd[k] * (w / total) for sd, w in zip(states, weights)\n",
        "            )\n",
        "        self.global_model.load_state_dict(new_state)\n",
        "\n",
        "    def distribute(self):\n",
        "        return {k: v.cpu().clone() for k, v in self.global_model.state_dict().items()}\n",
        "\n",
        "    def evaluate(self):\n",
        "        metrics = {}\n",
        "        for c in self.clients:\n",
        "            c.set_weights(self.distribute())\n",
        "            metrics[c.client_id] = c.evaluate_local()\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e52de7e4",
      "metadata": {
        "id": "e52de7e4"
      },
      "source": [
        "## Execução da Simulação\n",
        "\n",
        "Ajuste os caminhos dos CSVs abaixo (um por cliente)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ca615714",
      "metadata": {
        "id": "ca615714"
      },
      "outputs": [],
      "source": [
        "# Exemplo de configuração\n",
        "client_csvs = [\n",
        "    '/content/drive/MyDrive/Doutorado/Disciplina Isolada/PCC177/Projeto de Pesquisa/datasets/lat-15.35_lon-55.45_mt.csv',\n",
        "    '/content/drive/MyDrive/Doutorado/Disciplina Isolada/PCC177/Projeto de Pesquisa/datasets/lat-19.75_lon-44.45_mg.csv',\n",
        "    '/content/drive/MyDrive/Doutorado/Disciplina Isolada/PCC177/Projeto de Pesquisa/datasets/lat-2.15_lon-59.85_am.csv',\n",
        "    '/content/drive/MyDrive/Doutorado/Disciplina Isolada/PCC177/Projeto de Pesquisa/datasets/lat-30.75_lon-55.45_rs.csv',\n",
        "    '/content/drive/MyDrive/Doutorado/Disciplina Isolada/PCC177/Projeto de Pesquisa/datasets/lat-4.35_lon-40.05_ce.csv',\n",
        "    '/content/drive/MyDrive/Doutorado/Disciplina Isolada/PCC177/Projeto de Pesquisa/datasets/lat-8.75_lon-35.65_pe.csv'\n",
        "]\n",
        "\n",
        "target_col = 'ETo'\n",
        "seq_len = 4\n",
        "rounds = 5\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DLoPYy5ZRwF",
        "outputId": "78e96981-4ed9-4243-e632-bd268dd81b99"
      },
      "id": "4DLoPYy5ZRwF",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7f8449fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f8449fd",
        "outputId": "c8bb5842-61c9-4cf9-e8ad-ab0ec2ae01cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Round 1\n",
            "{'lat-15.35_lon-55.45_mt': {'rmse': 0.8149028994316663, 'mae': 0.6238318041079488, 'r2': 0.20332069920194695}, 'lat-19.75_lon-44.45_mg': {'rmse': 0.8826057638881883, 'mae': 0.6721318254097733, 'r2': 0.45763957860465543}, 'lat-2.15_lon-59.85_am': {'rmse': 0.9579543799495227, 'mae': 0.7488557158387026, 'r2': -0.24091231554870762}, 'lat-30.75_lon-55.45_rs': {'rmse': 1.4554817945170349, 'mae': 1.2491955683504627, 'r2': 0.3445034601045712}, 'lat-4.35_lon-40.05_ce': {'rmse': 1.2745177239325596, 'mae': 1.1088241364093536, 'r2': -0.07457800748362198}, 'lat-8.75_lon-35.65_pe': {'rmse': 0.7647238195789089, 'mae': 0.6396220438923832, 'r2': 0.4722235853807857}}\n",
            "\n",
            "Round 2\n",
            "{'lat-15.35_lon-55.45_mt': {'rmse': 0.7840045124386918, 'mae': 0.5949575658849272, 'r2': 0.26259015388755347}, 'lat-19.75_lon-44.45_mg': {'rmse': 0.8080124377395356, 'mae': 0.5990872874027585, 'r2': 0.5454406841309494}, 'lat-2.15_lon-59.85_am': {'rmse': 1.0058434233876783, 'mae': 0.795157094810135, 'r2': -0.3680822279375595}, 'lat-30.75_lon-55.45_rs': {'rmse': 1.3895622348750625, 'mae': 1.172826260512384, 'r2': 0.4025344712404748}, 'lat-4.35_lon-40.05_ce': {'rmse': 1.1732442133939824, 'mae': 1.022650534106839, 'r2': 0.08940967606376748}, 'lat-8.75_lon-35.65_pe': {'rmse': 0.716741199100804, 'mae': 0.5891759886509275, 'r2': 0.5363764577896106}}\n",
            "\n",
            "Round 3\n",
            "{'lat-15.35_lon-55.45_mt': {'rmse': 0.757333299946693, 'mae': 0.5719597095811538, 'r2': 0.31190894237943}, 'lat-19.75_lon-44.45_mg': {'rmse': 0.7650112912391267, 'mae': 0.5652986566089324, 'r2': 0.5925351396102911}, 'lat-2.15_lon-59.85_am': {'rmse': 0.9996184304498004, 'mae': 0.7883248527162927, 'r2': -0.35120097377623116}, 'lat-30.75_lon-55.45_rs': {'rmse': 1.3708383083868751, 'mae': 1.1534726608265895, 'r2': 0.4185273218333412}, 'lat-4.35_lon-40.05_ce': {'rmse': 1.173693411569213, 'mae': 1.0268298008708652, 'r2': 0.08871226999840232}, 'lat-8.75_lon-35.65_pe': {'rmse': 0.7216335559341052, 'mae': 0.5950980782099758, 'r2': 0.5300256214573092}}\n",
            "\n",
            "Round 4\n",
            "{'lat-15.35_lon-55.45_mt': {'rmse': 0.7502412006589593, 'mae': 0.5645585097756055, 'r2': 0.3247359513237127}, 'lat-19.75_lon-44.45_mg': {'rmse': 0.7625791087434808, 'mae': 0.5688634350762927, 'r2': 0.5951219080276079}, 'lat-2.15_lon-59.85_am': {'rmse': 0.9712757188019783, 'mae': 0.7641696506112753, 'r2': -0.2756645988788615}, 'lat-30.75_lon-55.45_rs': {'rmse': 1.3467830550423878, 'mae': 1.137317606252436, 'r2': 0.438755451621478}, 'lat-4.35_lon-40.05_ce': {'rmse': 1.2074354044608029, 'mae': 1.0596228423148046, 'r2': 0.03556269332995898}, 'lat-8.75_lon-35.65_pe': {'rmse': 0.7341010283317096, 'mae': 0.6099788787517142, 'r2': 0.5136460943890906}}\n",
            "\n",
            "Round 5\n",
            "{'lat-15.35_lon-55.45_mt': {'rmse': 0.7481196593196145, 'mae': 0.5627824296342566, 'r2': 0.32854959160406694}, 'lat-19.75_lon-44.45_mg': {'rmse': 0.7614044737076502, 'mae': 0.5684176885517149, 'r2': 0.5963682514033265}, 'lat-2.15_lon-59.85_am': {'rmse': 0.9860923076677978, 'mae': 0.7762702764839691, 'r2': -0.3148813994696187}, 'lat-30.75_lon-55.45_rs': {'rmse': 1.3604922232149923, 'mae': 1.1476378782857504, 'r2': 0.4272712615979718}, 'lat-4.35_lon-40.05_ce': {'rmse': 1.1839929061118073, 'mae': 1.036867092632642, 'r2': 0.07264847606631963}, 'lat-8.75_lon-35.65_pe': {'rmse': 0.721873996066966, 'mae': 0.5980285506749202, 'r2': 0.5297123889964125}}\n"
          ]
        }
      ],
      "source": [
        "# Execução\n",
        "clients = []\n",
        "for path in client_csvs:\n",
        "    df = pd.read_csv(path, sep=';')\n",
        "    cols = [c for c in df.columns if c != target_col and c.lower() != 'datetime']\n",
        "    cid = os.path.splitext(os.path.basename(path))[0]\n",
        "    clients.append(FLClient(cid, df, cols, target_col, seq_len, device=device))\n",
        "\n",
        "server = FLServer(clients, device=device)\n",
        "\n",
        "for r in range(rounds):\n",
        "    print(f'\\nRound {r+1}')\n",
        "    states, weights = [], []\n",
        "    global_w = server.distribute()\n",
        "    for c in clients:\n",
        "        c.set_weights(global_w)\n",
        "        c.local_train()\n",
        "        states.append(c.get_weights())\n",
        "        weights.append(c.n_samples)\n",
        "    server.aggregate(states, weights)\n",
        "    print(server.evaluate())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}